"""H√§mtar och sammanfattar nyheter med Gemini API och Google Search grounding."""

import json
from datetime import datetime, timedelta
from google import genai
from google.genai import types

from config import (
    GEMINI_API_KEY,
    COMPANY_CONTEXT,
    SEARCH_CATEGORIES,
    MAX_NEWS_ITEMS,
)
from utils.retry import retry_with_backoff
from sources.google_rss import fetch_news_from_rss, RSS_FEEDS


def create_client() -> genai.Client:
    """Skapar Gemini API-klient."""
    return genai.Client(api_key=GEMINI_API_KEY)


@retry_with_backoff(max_retries=3, base_delay=2.0, exceptions=(Exception,))
def fetch_news_for_category(
    client: genai.Client,
    category_key: str,
    category_config: dict,
    max_items: int = 4
) -> list[dict]:
    """
    H√§mtar nyheter f√∂r en specifik kategori med Google Search grounding.

    Returns:
        Lista med nyheter, varje nyhet √§r en dict med:
        - title: Rubrik
        - summary: Kort sammanfattning (2-3 meningar)
        - url: L√§nk till artikeln
        - source: K√§llans namn
        - relevance_score: 1-10 hur relevant f√∂r Svea Solar
    """

    queries_text = "\n".join(f"- {q}" for q in category_config["queries"])

    prompt = f"""
{COMPANY_CONTEXT}

S√∂k efter de senaste och mest relevanta nyheterna inom kategorin "{category_config['name']}"
med fokus p√• f√∂ljande s√∂ktermer:
{queries_text}

Hitta de {max_items} mest relevanta nyheterna fr√•n de senaste 7 dagarna.

KRITISKT OM URL:ER:
- Returnera ENDAST direkta l√§nkar till originalartiklar (t.ex. https://pv-magazine.com/2024/...)
- UNDVIK Google redirect-l√§nkar (vertexaisearch.cloud.google.com)
- Om du inte kan hitta en direkt URL, ange k√§llans huvuddom√§n (t.ex. https://www.reuters.com/)

F√∂r varje nyhet, returnera EXAKT f√∂ljande JSON-format (och inget annat):
{{
    "news": [
        {{
            "title": "Nyhetens exakta rubrik fr√•n artikeln",
            "summary": "Kort sammanfattning p√• 2-3 meningar som f√∂rklarar varf√∂r detta √§r relevant.",
            "url": "https://direktlank-till-artikel.com/...",
            "source": "K√§llans namn (t.ex. Reuters, PV Magazine, Energimyndigheten)",
            "published_date": "2025-11-28",
            "relevance_score": 8
        }}
    ]
}}

REGLER:
- published_date: Datum i format YYYY-MM-DD. Uppskatta om exakt datum saknas.
- relevance_score: 1-10 baserat p√• relevans f√∂r svensk IPP som bygger sol/batteriparker
- Prioritera: konkreta projekt >10 MW, investeringar, PPA-avtal, policy-√§ndringar, teknikgenombrott
- Undvik: produkter f√∂r privatpersoner, installationer <1 MW, opinionsartiklar
- Spr√•k: Beh√•ll originalspr√•ket (engelska/svenska) i sammanfattningen
- Format: Returnera ENDAST valid JSON, ingen markdown eller annan text
"""

    try:
        response = client.models.generate_content(
            model="gemini-2.5-pro",
            contents=prompt,
            config=types.GenerateContentConfig(
                tools=[types.Tool(google_search=types.GoogleSearch())],
                temperature=0.3,
            )
        )

        # Extrahera text fr√•n svaret
        if not response.candidates:
            print(f"  Inga kandidater i svar f√∂r {category_key}")
            return []

        # H√§mta text fr√•n response
        response_text = ""
        for part in response.candidates[0].content.parts:
            if hasattr(part, 'text') and part.text:
                response_text += part.text

        response_text = response_text.strip()

        # Hantera om svaret √§r wrappat i markdown code block
        if response_text.startswith("```"):
            lines = response_text.split("\n")
            # Ta bort f√∂rsta och sista raden (``` markers)
            json_lines = []
            in_json = False
            for line in lines:
                if line.startswith("```") and not in_json:
                    in_json = True
                    continue
                elif line.startswith("```") and in_json:
                    break
                elif in_json:
                    json_lines.append(line)
            response_text = "\n".join(json_lines)

        data = json.loads(response_text)
        news_items = data.get("news", [])

        # L√§gg till kategori-info p√• varje nyhet
        for item in news_items:
            item["category"] = category_key
            item["category_name"] = category_config["name"]
            item["category_emoji"] = category_config["emoji"]

        return news_items

    except json.JSONDecodeError as e:
        print(f"  Kunde inte parsa JSON f√∂r kategori {category_key}: {e}")
        print(f"  Svar: {response_text[:500] if response_text else 'Inget svar'}")
        return []
    except Exception as e:
        print(f"  Fel vid h√§mtning av nyheter f√∂r {category_key}: {e}")
        import traceback
        traceback.print_exc()
        return []


def filter_by_date(news_items: list, max_days: int = 7) -> tuple[list, int]:
    """
    Filtrerar bort nyheter som √§r √§ldre √§n max_days.

    Args:
        news_items: Lista med nyhetsartiklar
        max_days: Max antal dagar gamla nyheter att beh√•lla

    Returns:
        Tuple med (filtrerade nyheter, antal borttagna)
    """
    if not news_items:
        return [], 0

    cutoff_date = datetime.now() - timedelta(days=max_days)
    cutoff_str = cutoff_date.strftime("%Y-%m-%d")

    filtered = []
    removed = 0

    for item in news_items:
        pub_date = item.get("published_date", "")

        # Om inget datum finns, beh√•ll artikeln (kan vara ny)
        if not pub_date:
            filtered.append(item)
            continue

        # Parsa datumet
        try:
            # Hantera olika datumformat
            if len(pub_date) == 10:  # YYYY-MM-DD
                item_date = pub_date
            elif len(pub_date) > 10:  # L√§ngre format, ta bara datumdelen
                item_date = pub_date[:10]
            else:
                filtered.append(item)  # Ogiltig format, beh√•ll
                continue

            # J√§mf√∂r datum
            if item_date >= cutoff_str:
                filtered.append(item)
            else:
                removed += 1

        except (ValueError, TypeError):
            # Om datumparsning misslyckas, beh√•ll artikeln
            filtered.append(item)

    return filtered, removed


def fetch_all_news(max_age_days: int = 7) -> dict:
    """
    H√§mtar nyheter fr√•n alla kategorier och rankar dem.

    Returns:
        Dict med:
        - news_by_category: Dict med nyheter grupperade per kategori
        - top_news: Lista med de mest relevanta nyheterna totalt
        - fetch_date: Datum f√∂r h√§mtning
    """
    client = create_client()

    all_news = []
    news_by_category = {}

    # Ber√§kna hur m√•nga nyheter per kategori (f√∂rdela MAX_NEWS_ITEMS)
    num_categories = len(SEARCH_CATEGORIES)
    items_per_category = max(3, MAX_NEWS_ITEMS // num_categories)

    for category_key, category_config in SEARCH_CATEGORIES.items():
        print(f"H√§mtar nyheter f√∂r: {category_config['name']}...")

        news_items = fetch_news_for_category(
            client,
            category_key,
            category_config,
            max_items=items_per_category
        )

        news_by_category[category_key] = {
            "name": category_config["name"],
            "emoji": category_config["emoji"],
            "news_items": news_items
        }

        all_news.extend(news_items)

    # Komplettera med Google RSS om vi har f√• nyheter
    total_gemini = len(all_news)
    if total_gemini < MAX_NEWS_ITEMS:
        print(f"\nüì∞ Kompletterar med Google RSS ({total_gemini}/{MAX_NEWS_ITEMS} nyheter)...")
        rss_news = fetch_news_from_rss(max_per_feed=3)

        # Filtrera bort dubbletter (baserat p√• URL)
        existing_urls = {item.get("url") for item in all_news if item.get("url")}
        unique_rss = [item for item in rss_news if item.get("url") not in existing_urls]

        if unique_rss:
            print(f"   ‚úÖ Lade till {len(unique_rss)} unika RSS-nyheter")

            # L√§gg till RSS-nyheter i en egen kategori eller f√∂rdela
            if "rss_news" not in news_by_category:
                news_by_category["rss_news"] = {
                    "name": "Fler nyheter (RSS)",
                    "emoji": "üì∞",
                    "news_items": unique_rss
                }
            all_news.extend(unique_rss)

    # Filtrera bort gamla nyheter
    total_before_date_filter = len(all_news)
    total_old_removed = 0

    for cat_key, cat_data in news_by_category.items():
        filtered, removed = filter_by_date(cat_data["news_items"], max_days=max_age_days)
        cat_data["news_items"] = filtered
        total_old_removed += removed

    if total_old_removed > 0:
        print(f"\nüìÖ Datumfilter: {total_old_removed} gamla nyheter borttagna (√§ldre √§n {max_age_days} dagar)")

    # Uppdatera all_news efter datumfiltrering
    all_news = [
        item
        for cat in news_by_category.values()
        for item in cat["news_items"]
    ]

    # Sortera alla nyheter efter relevans
    all_news_sorted = sorted(
        all_news,
        key=lambda x: x.get("relevance_score", 0),
        reverse=True
    )

    # Ta topp MAX_NEWS_ITEMS
    top_news = all_news_sorted[:MAX_NEWS_ITEMS]

    return {
        "news_by_category": news_by_category,
        "top_news": top_news,
        "fetch_date": datetime.now().strftime("%Y-%m-%d"),
        "fetch_time": datetime.now().strftime("%H:%M"),
    }


def generate_weekly_insights(news_data: dict) -> dict:
    """
    Genererar AI-baserade insikter fr√•n veckans nyheter.

    Args:
        news_data: Dict med news_by_category

    Returns:
        Dict med trends, company_context, predictions
    """
    client = create_client()

    # Sammanst√§ll alla nyheter som kontext
    all_news_text = ""
    for cat in news_data["news_by_category"].values():
        all_news_text += f"\n## {cat['name']}\n"
        for item in cat["news_items"]:
            all_news_text += f"- {item['title']}: {item['summary']}\n"

    prompt = f"""
Analysera dessa nyheter fr√•n sol- och batteribranschen den senaste veckan:

{all_news_text}

Som strategisk analytiker f√∂r Svea Solar (svensk IPP som bygger sol- och batteriparker), generera:

1. OBSERVERADE TRENDER (4-6 punkter):
   - Vilka m√∂nster ser du i nyheterna?
   - Geografiska, teknologiska eller marknadsm√§ssiga trender?
   - Vad har h√§nt inom batterilagring?

2. RELEVANS F√ñR SVEA SOLAR (4-6 punkter):
   - Hur p√•verkar dessa nyheter en svensk solparks-utvecklare?
   - Konkurrentr√∂relser att bevaka?
   - M√∂jligheter eller risker?

3. MARKNADSUTSIKTER (3-4 punkter):
   - Vad indikerar nyheterna om framtiden?
   - Prisf√∂r√§ndringar eller investeringsl√§ge?
   - Regulatoriska f√∂r√§ndringar att bevaka?

Returnera som JSON (och ENDAST JSON, ingen annan text):
{{
    "trends": ["...", "...", "..."],
    "company_context": ["...", "...", "..."],
    "predictions": ["...", "..."]
}}

Skriv p√• svenska. Var konkret och specifik - referera till faktiska nyheter och siffror.
"""

    try:
        response = client.models.generate_content(
            model="gemini-2.5-pro",
            contents=prompt,
            config=types.GenerateContentConfig(
                temperature=0.5,
            )
        )

        response_text = ""
        for part in response.candidates[0].content.parts:
            if hasattr(part, 'text') and part.text:
                response_text += part.text

        response_text = response_text.strip()

        # Hantera markdown code block
        if response_text.startswith("```"):
            lines = response_text.split("\n")
            json_lines = []
            in_json = False
            for line in lines:
                if line.startswith("```") and not in_json:
                    in_json = True
                    continue
                elif line.startswith("```") and in_json:
                    break
                elif in_json:
                    json_lines.append(line)
            response_text = "\n".join(json_lines)

        insights = json.loads(response_text)

        return {
            "trends": insights.get("trends", []),
            "company_context": insights.get("company_context", []),
            "predictions": insights.get("predictions", []),
        }

    except Exception as e:
        print(f"Fel vid generering av AI-insikter: {e}")
        return {
            "trends": ["Kunde inte generera trender automatiskt."],
            "company_context": ["Kunde inte generera f√∂retagskontext automatiskt."],
            "predictions": ["Kunde inte generera prognoser automatiskt."],
        }


if __name__ == "__main__":
    # Test
    from dotenv import load_dotenv
    load_dotenv()

    result = fetch_all_news()
    print(f"\nH√§mtade {len(result['top_news'])} nyheter totalt")

    for category_key, category_data in result["news_by_category"].items():
        print(f"\n{category_data['emoji']} {category_data['name']}: {len(category_data['news_items'])} nyheter")
        for item in category_data["news_items"]:
            print(f"  - [{item.get('relevance_score', '?')}] {item['title'][:60]}...")
